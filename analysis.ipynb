{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import branca.colormap as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Step 1: Load Dataset ---\n",
    "# URL for the California Housing dataset\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "print(\"Status: Downloading dataset...\")\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(f\"Success: Dataset loaded with {len(df)} records.\")\n",
    "# Display first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f046de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: GIS Feature Engineering ---\n",
    "# Goal: Calculate the precise geodesic distance from each property to the nearest coastline.\n",
    "\n",
    "# Convert DataFrame to GeoDataFrame\n",
    "# Initial CRS: EPSG:4326 (WGS84 - Latitude/Longitude)\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "print(\"Status: Fetching California coastline data...\")\n",
    "# Load California counties boundary from public GeoJSON\n",
    "ca_url = \"https://raw.githubusercontent.com/codeforgermany/click_that_hood/main/public/data/california-counties.geojson\"\n",
    "ca_counties = gpd.read_file(ca_url)\n",
    "\n",
    "# --- CRITICAL FIX: Topology Repair ---\n",
    "print(\"Status: Repairing topology errors (Buffer 0 fix)...\")\n",
    "# Fix self-intersection or invalid geometries to prevent dissolve errors\n",
    "ca_counties['geometry'] = ca_counties.geometry.buffer(0)\n",
    "\n",
    "# Dissolve counties to get the outer boundary of California\n",
    "print(\"Status: Dissolving boundaries...\")\n",
    "ca_boundary = ca_counties.dissolve()\n",
    "\n",
    "# Reproject to EPSG:3310 (California Albers) for accurate meter-based distance calculation\n",
    "print(\"Status: Reprojecting to EPSG:3310 (Meters)...\")\n",
    "gdf = gdf.to_crs(\"EPSG:3310\")\n",
    "ca_boundary = ca_boundary.to_crs(\"EPSG:3310\")\n",
    "\n",
    "# Extract the boundary line\n",
    "coastline = ca_boundary.boundary\n",
    "\n",
    "print(\"Status: Calculating distance to coast (this may take a moment)...\")\n",
    "# Calculate distance for every point\n",
    "gdf['dist_to_coast'] = gdf.geometry.apply(lambda x: coastline.distance(x))\n",
    "\n",
    "# Convert back to standard DataFrame for Machine Learning\n",
    "df_ml = pd.DataFrame(gdf.drop(columns='geometry'))\n",
    "# Convert meters to kilometers for better readability\n",
    "df_ml['dist_to_coast_km'] = df_ml['dist_to_coast'] / 1000 \n",
    "\n",
    "print(\"Success: GIS Feature Engineering complete.\")\n",
    "print(df_ml[['longitude', 'latitude', 'median_house_value', 'dist_to_coast_km']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ebb887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Data Preparation & Modeling ---\n",
    "\n",
    "# Feature Selection:\n",
    "# Remove target variable, old categorical column, and the raw meter-distance column\n",
    "X = df_ml.drop(columns=['median_house_value', 'ocean_proximity', 'dist_to_coast'])\n",
    "\n",
    "# Handle missing values (Simple imputation with mean)\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "y = df_ml['median_house_value']\n",
    "\n",
    "# Split data into Training and Testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and Train XGBoost Regressor\n",
    "# Using version 1.7.6 for compatibility with SHAP\n",
    "print(\"Status: Training XGBoost Model...\")\n",
    "model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"Success: Model RÂ² Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Model Explainability (SHAP Analysis) ---\n",
    "\n",
    "print(\"Status: Calculating SHAP values...\")\n",
    "\n",
    "# Initialize TreeExplainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# --- Visualization: Optimized Beeswarm Plot ---\n",
    "# Downsampling to avoid overplotting and improve clarity\n",
    "limit = 2000\n",
    "if X_test.shape[0] > limit:\n",
    "    indices = np.random.choice(X_test.shape[0], limit, replace=False)\n",
    "    shap_subset = shap_values[indices]\n",
    "    X_subset = X_test.iloc[indices]\n",
    "else:\n",
    "    shap_subset = shap_values\n",
    "    X_subset = X_test\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_subset, X_subset, \n",
    "                  max_display=10, \n",
    "                  alpha=0.6, \n",
    "                  plot_size=(10, 6),\n",
    "                  show=False)\n",
    "\n",
    "# Add English Labels\n",
    "plt.title(\"Feature Impact on House Prices\", fontsize=16, pad=20)\n",
    "plt.xlabel(\"SHAP Value (Impact on Price Output)\", fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "print(\"Displaying SHAP Summary Plot:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, \n",
    "                  plot_type=\"bar\", \n",
    "                  max_display=10, \n",
    "                  color='#007acc', \n",
    "                  show=False)\n",
    "\n",
    "plt.title(\"Average Impact Magnitude of Features\", fontsize=16, pad=20)\n",
    "plt.xlabel(\"Average |SHAP Value| (Mean Impact on Price)\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048fe1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Interactive Geospatial Visualization ---\n",
    "# Goal: Visualize the \"Location Premium\" (Pure spatial contribution to price)\n",
    "\n",
    "print(\"Status: Generating interactive map with legend...\")\n",
    "\n",
    "# 1. Sampling for performance\n",
    "sample_size = 2000 \n",
    "actual_size = min(sample_size, len(X_test))\n",
    "indices = np.random.choice(X_test.index, size=actual_size, replace=False)\n",
    "\n",
    "# 2. Extract Data\n",
    "lat_idx = X_test.columns.get_loc('latitude')\n",
    "lon_idx = X_test.columns.get_loc('longitude')\n",
    "dist_idx = X_test.columns.get_loc('dist_to_coast_km')\n",
    "\n",
    "subset_shap = shap_values[np.isin(X_test.index, indices)]\n",
    "\n",
    "# Calculate Location Premium: Sum of Latitude, Longitude, and Distance-to-Coast effects\n",
    "location_impact = subset_shap[:, lat_idx] + subset_shap[:, lon_idx] + subset_shap[:, dist_idx]\n",
    "\n",
    "# Define range for the legend\n",
    "min_val = np.min(location_impact)\n",
    "max_val = np.max(location_impact)\n",
    "\n",
    "# Prepare coordinates\n",
    "lat_data = X_test.loc[indices, 'latitude'].values\n",
    "lon_data = X_test.loc[indices, 'longitude'].values\n",
    "\n",
    "# 3. Create Base Map\n",
    "m = folium.Map(location=[36.7, -119.4], zoom_start=6, tiles='CartoDB dark_matter')\n",
    "\n",
    "# 4. Add Color Legend (Red = High Premium, Blue = Negative Impact)\n",
    "colormap = cm.LinearColormap(\n",
    "    colors=['blue', 'cyan', 'lime', 'yellow', 'red'],\n",
    "    vmin=min_val,\n",
    "    vmax=max_val,\n",
    "    caption='Location Premium (Net Impact on Price in USD)' \n",
    ")\n",
    "m.add_child(colormap)\n",
    "\n",
    "# 5. Prepare Data for HeatMap (Fixing float32 serialization issue)\n",
    "data_heat = []\n",
    "for i in range(len(lat_data)):\n",
    "    # Explicitly convert numpy types to standard python floats\n",
    "    lat = float(lat_data[i])\n",
    "    lon = float(lon_data[i])\n",
    "    weight = float(location_impact[i])\n",
    "    \n",
    "    # Normalize weight to 0-1 range for the heatmap gradient\n",
    "    normalized_weight = (weight - min_val) / (max_val - min_val)\n",
    "    \n",
    "    data_heat.append([lat, lon, normalized_weight])\n",
    "\n",
    "# 6. Add HeatMap Layer\n",
    "HeatMap(data_heat, radius=15, blur=20, \n",
    "        gradient={0.0: 'blue', 0.25: 'cyan', 0.5: 'lime', 0.75: 'yellow', 1.0: 'red'}).add_to(m)\n",
    "\n",
    "print(f\"Success: Map generated! Value range: ${min_val:.0f} to ${max_val:.0f}\")\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
